{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scaling import standardize, normalize\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015 = pd.read_csv('../data/kaasa/kaasa_2015.csv', index_col=None, header=0)\n",
    "df2016 = pd.read_csv('../data/kaasa/kaasa_2016.csv', index_col=None, header=0)\n",
    "df2017 = pd.read_csv('../data/kaasa/kaasa_2017.csv', index_col=None, header=0)\n",
    "df2018 = pd.read_csv('../data/kaasa/kaasa_2018.csv', index_col=None, header=0)\n",
    "df2019 = pd.read_csv('../data/kaasa/kaasa_2019.csv', index_col=None, header=0)\n",
    "df2020 = pd.read_csv('../data/kaasa/kaasa_2020.csv', index_col=None, header=0)\n",
    "df2021 = pd.read_csv('../data/kaasa/kaasa_2021.csv', index_col=None, header=0)\n",
    "\n",
    "all_files = [df2015, df2016, df2017, df2018, df2019, df2020, df2021]\n",
    "\n",
    "df = pd.concat(all_files, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['source_id', 'individual', 'owner_id', 'name',  'distance', 'sin_time', 'cos_time', 'date_time',\n",
    "                      'longitude', 'latitude', 'temperature', 'altitude'])\n",
    "\n",
    "df = standardize(df, ['velocity', 'angle']) # standarize the data\n",
    "df = normalize(df, ['velocity', 'angle'], 0, 1) # normalize the data\n",
    "\n",
    "X = df.drop(['attack'], axis=1) # Features\n",
    "y = df['attack'] # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('attack', axis=1), df['attack'], test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With no oversampling and no hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9793 (+/- 0.0003)\n",
      "precision: 0.0152 (+/- 0.0227)\n",
      "recall: 0.0075 (+/- 0.0119)\n",
      "f1: 0.0101 (+/- 0.0156)\n",
      "roc_auc: 0.5105 (+/- 0.0101)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the metrics you want to score on\n",
    "scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Perform K-fold cross-validation and get the scores on each fold\n",
    "scores = cross_validate(rf, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "# Print the average scores and their standard deviations\n",
    "for metric in scoring:\n",
    "    print(\"%s: %0.4f (+/- %0.4f)\" % (metric, scores['test_'+metric].mean(), scores['test_'+metric].std() * 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With hyperparameter tuning and no oversampling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9796 (+/- 0.0007)\n",
      "precision: 0.0159 (+/- 0.0179)\n",
      "recall: 0.0075 (+/- 0.0094)\n",
      "f1: 0.0102 (+/- 0.0124)\n",
      "roc_auc: 0.5077 (+/- 0.0080)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, max_depth=100, class_weight='balanced_subsample', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define the metrics you want to score on\n",
    "scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Perform K-fold cross-validation and get the scores on each fold\n",
    "scores = cross_validate(rf, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "# Print the average scores and their standard deviations\n",
    "for metric in scoring:\n",
    "    print(\"%s: %0.4f (+/- %0.4f)\" % (metric, scores['test_'+metric].mean(), scores['test_'+metric].std() * 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With oversampling and no hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8778 (+/- 0.0065)\n",
      "precision: 0.0133 (+/- 0.0018)\n",
      "recall: 0.1047 (+/- 0.0137)\n",
      "f1: 0.0237 (+/- 0.0031)\n",
      "roc_auc: 0.5126 (+/- 0.0074)\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline with SMOTE oversampling and random forest classifier\n",
    "pipeline = Pipeline([\n",
    "    ('sampling', SMOTE()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the stratified k-fold cross-validation object\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "# Perform K-fold cross-validation and get the scores on each fold\n",
    "scores = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "# Print the average scores and their standard deviations\n",
    "for metric in scoring:\n",
    "    print(\"%s: %0.4f (+/- %0.4f)\" % (metric, scores['test_'+metric].mean(), scores['test_'+metric].std() * 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With oversampling and hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8777 (+/- 0.0058)\n",
      "precision: 0.0156 (+/- 0.0031)\n",
      "recall: 0.1231 (+/- 0.0227)\n",
      "f1: 0.0277 (+/- 0.0054)\n",
      "roc_auc: 0.5135 (+/- 0.0224)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline with SMOTE oversampling and random forest classifier\n",
    "pipeline = Pipeline([\n",
    "    ('sampling', SMOTE()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=300, max_depth=100, class_weight='balanced_subsample', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Define the stratified k-fold cross-validation object\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "# Perform K-fold cross-validation and get the scores on each fold\n",
    "scores = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "# Print the average scores and their standard deviations\n",
    "for metric in scoring:\n",
    "    print(\"%s: %0.4f (+/- %0.4f)\" % (metric, scores['test_'+metric].mean(), scores['test_'+metric].std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
